<div align="center">
   <h1><b>Tradutor de Libras</b></h1><br><br>

   <a href="" target="_blank">![License](https://img.shields.io/badge/license-MIT-blue.svg)</a>
   ![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)

</div>


## ğŸ“– DescriÃ§Ã£o

**SignTranslator** Ã© uma aplicaÃ§Ã£o de traduÃ§Ã£o em tempo real da LÃ­ngua Brasileira de Sinais (Libras) desenvolvida em Python. Utilizando a webcam, a aplicaÃ§Ã£o analisa os movimentos das mÃ£os do usuÃ¡rio e identifica as letras correspondentes em Libras, facilitando a comunicaÃ§Ã£o entre surdos e ouvintes atravÃ©s de tecnologia avanÃ§ada de visÃ£o computacional e aprendizado de mÃ¡quina.

<br>

## âš™ï¸ Funcionalidades

- **DetecÃ§Ã£o de MÃ£os:** Identifica e rastreia as mÃ£os do usuÃ¡rio em tempo real usando a webcam.
- **Reconhecimento de Letras em Libras:** Analisa os gestos das mÃ£os e identifica a letra correspondente na Libras.
- **Interface GrÃ¡fica Intuitiva:** Interface amigÃ¡vel para iniciar e monitorar o processo de reconhecimento.
- **Treinamento de Modelo Personalizado:** Permite treinar o modelo com um conjunto de dados especÃ­fico para melhorar a precisÃ£o.
- **PrevisÃ£o em Tempo Real:** Exibe a letra identificada diretamente na interface durante o uso.

<br>

## ğŸ›  Tecnologias Utilizadas

- **Python 3.8+**
- **OpenCV:** Biblioteca de visÃ£o computacional para captura e processamento de vÃ­deo.
- **Mediapipe:** Framework para detecÃ§Ã£o e rastreamento de mÃ£os.
- **TensorFlow/Keras:** Frameworks de aprendizado de mÃ¡quina utilizados para treinar e executar o modelo de reconhecimento.
- **NumPy:** ManipulaÃ§Ã£o de arrays e operaÃ§Ãµes matemÃ¡ticas.
- **Tkinter:** Biblioteca para criaÃ§Ã£o da interface grÃ¡fica.
- **Pandas:** ManipulaÃ§Ã£o e anÃ¡lise de dados.

<br>

## ğŸ’¾ InstalaÃ§Ã£o

### PrÃ©-requisitos

- **Python 3.8 ou superior** instalado em sua mÃ¡quina. [Baixe aqui](https://www.python.org/downloads/).
- **pip** para gerenciar pacotes Python.

### Passos de InstalaÃ§Ã£o

1. **Clone este repositÃ³rio:**

   ```bash
   git clone https://github.com/LuccaGiovane/SignTranslator.git
   ```
2. **Navegue atÃ© o diretÃ³rio do projeto:**
   ```bash
   cd SignTranslator
   ```
3. **Crie e ative um ambiente virtual (opcional, mas recomendado):**
   ```bash
   python -m venv venv
   ```
   3.1. **Windows:**
   ```bash
   venv\Scripts\activate
   ```
   3.2. **macOS/Linux:**
   ```bash
   source venv/bin/activate
   ```
4. **Instale as dependÃªncias necessÃ¡rias:**
   ```bash
   pip install -r requirements.txt
   ```
   
<br>

## ğŸš€ Uso
### Treinamento do Modelo
Antes de utilizar a aplicaÃ§Ã£o para reconhecimento em tempo real, Ã© necessÃ¡rio treinar o modelo com os dados de sinais em Libras.

1. Prepare o Dataset:
- Baixe o dataset [Libras CNN](https://www.kaggle.com/datasets/allanpardinho/libras-cnn) da Kaggle.
- Extraia e organize os dados nos diretÃ³rios dataset/train e dataset/test conforme a estrutura esperada pelo script train.py.

2. **Execute o Script de Treinamento:**
   ```bash
   python train.py
   ```
- O treinamento pode levar algum tempo dependendo do seu hardware.
- ApÃ³s o treinamento, o modelo serÃ¡ salvo como model.h5.
  
<br>

## ğŸ‘¨ğŸ»â€ğŸ’» Executando a AplicaÃ§Ã£o
1. Inicie a interface GrÃ¡fica:
   ```bash
   python main.py
   ```
2. Na Interface:
- Clique no botÃ£o "Iniciar" para comeÃ§ar o reconhecimento em tempo real.
- A aplicaÃ§Ã£o acessarÃ¡ a webcam e comeÃ§arÃ¡ a identificar as letras em Libras baseadas nos gestos das suas mÃ£os.
- Pressione 'q' na janela de vÃ­deo para encerrar o reconhecimento.

<br>

## ğŸ“Š Dataset de Treinamento para Libras
Foi utilizado o dataset [Libras CNN](https://www.kaggle.com/datasets/allanpardinho/libras-cnn), que contÃ©m milhares de imagens de mÃ£os em diferentes posiÃ§Ãµes correspondentes Ã s letras da Libras. Este dataset foi fundamental para treinar o modelo de reconhecimento, garantindo maior precisÃ£o e eficiÃªncia na identificaÃ§Ã£o dos gestos.

<br>

## ğŸ¤ ContribuiÃ§Ã£o
ContribuiÃ§Ãµes sÃ£o bem-vindas! Se vocÃª deseja melhorar este projeto, siga as etapas abaixo:

1. Fork este repositÃ³rio.
1. Crie uma branch para sua feature:
   ```bash
   git checkout -b feature/nova-feature
   ```
3. FaÃ§a commit das suas alteraÃ§Ãµes:
   ```bash
   git commit -m "Adiciona nova feature"
   ```
4. Envie para a branch:
   ```bash
   git push origin feature/nova-feature
   ```
5. abra um Pull Request.

<br> 

## ğŸ“‚ Estrutura do Projeto
```bash
SignTranslator/
â”‚
â”œâ”€â”€ img/
â”‚   â””â”€â”€ octocat.png
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ hand_recognition.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ model.h5
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

<br>

- **img/:** DiretÃ³rio para imagens utilizadas na interface grÃ¡fica.
- **scripts/:** Scripts para reconhecimento de mÃ£os e treinamento do modelo.
- **dataset/:** Conjunto de dados para treinamento e teste.
- **main.py:** Script principal para a interface grÃ¡fica.
- **requirements.txt:** Lista de dependÃªncias do projeto.
